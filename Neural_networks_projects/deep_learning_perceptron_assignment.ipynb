{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, fbeta_score\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.datasets import load_breast_cancer, load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import datasets and load them as pandas frames\n",
    "\n",
    "iris_set = load_iris()\n",
    "breast_cancer_set = load_breast_cancer()\n",
    "\n",
    "iris_raw = pd.DataFrame(iris_set.data, columns=iris_set.feature_names)\n",
    "breast_cancer_raw = pd.DataFrame(breast_cancer_set.data, columns=breast_cancer_set.feature_names)\n",
    "\n",
    "breast_cancer_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the targets also\n",
    "iris_target = iris_set['target']\n",
    "breast_cancer_target = breast_cancer_set['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick exploration and rule setting\n",
    "\n",
    "From `sklearn description` it appears that both dataset labels are fairly balanced (40-60 at worse) in the case of iris are perfectly balanced. \n",
    "\n",
    "So for the iris we will pick straight **accuracy** as our evaluation metric,since we don't have significant interest on putting more weight of importance on predicting a specific class better than the other.\n",
    "\n",
    "For the breast cancer, surely we are more interested in true positives, and false negatives. So we are mostly interested on prediction positive cases. So recall would be our first priority here, but because we want to be careful and not classify also people with no cancer as positive, we will pick some kind of mean between recall and precision, with a weight towards recall, namely **f2_score**.\n",
    "\n",
    "#### Scaling\n",
    "\n",
    "Last but not least, after splitting the data (for both training and test set) we will scale numerical columns to values between 0 and 1. This scaled version of both datasets will be used only for the perceptron training. The logic behind this action is that although both are linear models, and each input will have it's corresponding co-efficient, when updating the weights in perceptron training after a miss-classified point, we want the update to be as smooth as it gets and not to depend on extreme values because a unit is bigger than the other. So we make the change a bit less sensitive (since the input of the new point to be added/removed will be scaled down).\n",
    "\n",
    "#### Note\n",
    "\n",
    "We could also avoid to scale down Iris since all of it's independent variables are in the same scale (cm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    float64\n",
      "sepal width (cm)     float64\n",
      "petal length (cm)    float64\n",
      "petal width (cm)     float64\n",
      "dtype: object\n",
      "mean radius                float64\n",
      "mean texture               float64\n",
      "mean perimeter             float64\n",
      "mean area                  float64\n",
      "mean smoothness            float64\n",
      "mean compactness           float64\n",
      "mean concavity             float64\n",
      "mean concave points        float64\n",
      "mean symmetry              float64\n",
      "mean fractal dimension     float64\n",
      "radius error               float64\n",
      "texture error              float64\n",
      "perimeter error            float64\n",
      "area error                 float64\n",
      "smoothness error           float64\n",
      "compactness error          float64\n",
      "concavity error            float64\n",
      "concave points error       float64\n",
      "symmetry error             float64\n",
      "fractal dimension error    float64\n",
      "worst radius               float64\n",
      "worst texture              float64\n",
      "worst perimeter            float64\n",
      "worst area                 float64\n",
      "worst smoothness           float64\n",
      "worst compactness          float64\n",
      "worst concavity            float64\n",
      "worst concave points       float64\n",
      "worst symmetry             float64\n",
      "worst fractal dimension    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Let's find types of our dataframes columns\n",
    "\n",
    "print(iris_raw.dtypes)\n",
    "print(breast_cancer_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of the columns are numerical and we don't deal with categorical variables or strings to hot encode, we will proceed with the train_test_split (and a random_state so we have the same always) and the both train and test set scales. So we have two different version for logistic regression and our perceptron as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test sets\n",
    "\n",
    "iris_X_train, iris_X_test, iris_Y_train, iris_Y_test = train_test_split(iris_raw, iris_target, test_size=0.35, random_state=323)\n",
    "breast_cancer_X_train, breast_cancer_X_test, breast_cancer_Y_train, breast_cancer_Y_test = train_test_split(breast_cancer_raw, breast_cancer_target, test_size=0.35, random_state=313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale using minmax scaler for perceptron\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "breast_X_train_scaled = min_max_scaler.fit_transform(breast_cancer_X_train)\n",
    "breast_X_test_scaled = min_max_scaler.fit_transform(breast_cancer_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let the training begin\n",
    "\n",
    "We will start with the iris dataset, first logisitic regression and then the perceptron. To answer the question we will try to apply the same hyperparameters to estimate which algorithm performs better and then having put that out of the way, we will try and tune perceptron a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9811320754716981\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression with iris\n",
    "\n",
    "lr_model = LogisticRegression(penalty=\"elasticnet\", l1_ratio=0.5, solver=\"saga\", max_iter=2000, random_state=101).fit(iris_X_train, iris_Y_train)\n",
    "lr_predictions = lr_model.predict(iris_X_test)\n",
    "print(accuracy_score(iris_Y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33962264150943394\n"
     ]
    }
   ],
   "source": [
    "# Train our perceptron model \n",
    "\n",
    "prct_model = Perceptron(penalty=\"elasticnet\", l1_ratio=0.5, max_iter=300, random_state=105).fit(iris_X_train, iris_Y_train)\n",
    "prct_predictions = prct_model.predict(iris_X_test)\n",
    "print(accuracy_score(iris_Y_test, prct_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First impressions\n",
    "\n",
    "Logistic regressions appears far more stable no matter what the parameters passed are, predicted accuracy comes close to 98% almost all of the times. We have tried different combinations of **lasso l1**, **ridge l2** and combined **elasticnet** regularization as a method to penalize the slope, and the outcome is the same. \n",
    "\n",
    "At the same time percpetron seems very sensible to hyperparameter tuning, not only the type of slope penalty we apply, but also to the **lambda** ratio that adjusts the penalty. The variation of accuracy comes from as low as **33%** as high as **92%** as we will demonstrate below with a fine l1_ratio tuning. \n",
    "\n",
    "#### Note:\n",
    "\n",
    "A positive side I noticed is that perceptron model takes a lot smaller iterations to converge than equivalent logistic regression. Depends also a lot on the solver, the dataset, if it's multinomial or not, it's size and more, but for now pound to pound it appeared to me that perceptron converged significantly faster, no matter the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9245283018867925\n"
     ]
    }
   ],
   "source": [
    "# Train our perceptron model with optimal l1_ratio\n",
    "\n",
    "prct_model = Perceptron(penalty=\"elasticnet\", l1_ratio=0.9, max_iter=300, random_state=105).fit(iris_X_train, iris_Y_train)\n",
    "prct_predictions = prct_model.predict(iris_X_test)\n",
    "print(accuracy_score(iris_Y_test, prct_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome thoughts\n",
    "\n",
    "Specifically for this dataset, logistic regression appears to be not only more stable, but also more accurate in any case we tried. Perceptron has it's ups and down's and with fine tuning and correct regularization can also be very competitive, but also very sensitive, which is giving me thoughts if there is an **overfitting** pattern and it just performs better in some cases because the sample size it's small and it just fits better with these params. (for example try to adjust the l1_ratio from 0.9 to either 0.8 or to 1 and hell unleashes).\n",
    "\n",
    "On to the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression with breast cancer not scaled\n",
    "\n",
    "lr_model = LogisticRegression(penalty=\"elasticnet\", l1_ratio=0.5, solver=\"saga\",max_iter=4000, random_state=101).fit(breast_cancer_X_train, breast_cancer_Y_train)\n",
    "lr_predictions = lr_model.predict(breast_cancer_X_test)\n",
    "print(fbeta_score(breast_cancer_Y_test, lr_predictions, average=\"micro\", beta=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try the scaled features for perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9200000000000002\n"
     ]
    }
   ],
   "source": [
    "# Train our perceptron model non scaled\n",
    "\n",
    "prct_model = Perceptron(penalty=\"elasticnet\", l1_ratio=0.9, max_iter=300, random_state=105).fit(breast_cancer_X_train, breast_cancer_Y_train)\n",
    "prct_predictions = prct_model.predict(breast_cancer_X_test)\n",
    "print(fbeta_score(breast_cancer_Y_test, prct_predictions, average=\"micro\", beta=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "# Train our perceptron model scaled data\n",
    "\n",
    "prct_model = Perceptron(penalty=\"elasticnet\", l1_ratio=0.9, max_iter=300, random_state=105).fit(breast_X_train_scaled, breast_cancer_Y_train)\n",
    "prct_predictions = prct_model.predict(breast_X_test_scaled)\n",
    "print(fbeta_score(breast_cancer_Y_test, prct_predictions, average=\"micro\", beta=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A significant improvement based on the scaled features\n",
    "\n",
    "But maybe it was a co-incidence let's try and have a look with an **l2** ridge type of regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# Train our perceptron model scaled data\n",
    "\n",
    "prct_model = Perceptron(penalty=\"l2\", max_iter=300, random_state=105).fit(breast_X_train_scaled, breast_cancer_Y_train)\n",
    "prct_predictions = prct_model.predict(breast_X_test_scaled)\n",
    "print(fbeta_score(breast_cancer_Y_test, prct_predictions, average=\"micro\", beta=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# Let's see how logistic regression classifier performs under l2, \n",
    "\n",
    "# train logistic regression with breast cancer not scaled\n",
    "\n",
    "lr_model = LogisticRegression(penalty=\"l2\", max_iter=4000, random_state=101).fit(breast_cancer_X_train, breast_cancer_Y_train)\n",
    "lr_predictions = lr_model.predict(breast_cancer_X_test)\n",
    "print(fbeta_score(breast_cancer_Y_test, lr_predictions, average=\"micro\", beta=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on the outcome\n",
    "\n",
    "For the second dataset we can conclude that for both classifiers the penalty set to **L2** helped significantly (regardless of changing the score, with accuracy worked the same). This may have to do due to the change of the solver (probably **saga** solver does not produce the same results with elastic net config here). \n",
    "\n",
    "Scaling also improved our perceptron model, to achieve high **f2_score** accuracy and perform slightly better than logistic regression on this dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
